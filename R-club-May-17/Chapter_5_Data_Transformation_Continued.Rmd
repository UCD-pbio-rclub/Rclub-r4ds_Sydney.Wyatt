---
title: "Chapter 5: Data Transformation, Continued"
output: 
  html_document: 
    keep_md: yes
---
```{r,include=FALSE}
library(tidyverse)
library(nycflights13)
```

##5.6 Grouped summaries with `summarise()`

`summarise()` collapses data frames to a single row. Example:
```{r}
summarise(flights, delay = mean(dep_delay, na.rm = TRUE))
```

`summarise()` is more useful when used with `group_by()` because it analyzes individual groups instead of the whole dataset. Example:
```{r}
#Get average delay per date
by_day <- group_by(flights, year, month, day)
summarise(by_day, delay = mean(dep_delay, na.rm = TRUE))
```

###5.6.1 Combining multiple operations with the pipe

Can do it this way:
```{r}
by_dest <- group_by(flights, dest)
delay <- summarise(by_dest,
  count = n(),
  dist = mean(distance, na.rm = TRUE),
  delay = mean(arr_delay, na.rm = TRUE)
)
delay <- filter(delay, count > 20, dest != "HNL")

# It looks like delays increase with distance up to ~750 miles 
# and then decrease. Maybe as flights get longer there's more 
# ability to make up delays in the air?
ggplot(data = delay, mapping = aes(x = dist, y = delay)) +
  geom_point(aes(size = count), alpha = 1/3) +
  geom_smooth(se = FALSE)
#> `geom_smooth()` using method = 'loess'
```

Where there are three steps to prepare the data: group flights by destination; summarise to compute distance, average delay, and number of flights; filter to remove noisy points and Honolulu airport, which is almost twice as far away as the next closest airport. Try again using the pipe (`%>%`):
```{r}
delays <- flights %>% 
  group_by(dest) %>% 
  summarise(
    count = n(),
    dist = mean(distance, na.rm = TRUE),
    delay = mean(arr_delay, na.rm = TRUE)
  ) %>% 
  filter(count > 20, dest != "HNL")
```

This reads group, then summarise, then filter. This vastly improves the readability of the code. BUT `ggplot2` does not work with the pipe.

###5.6.2 Missing values

All aggregation functions have an `na.rm` argument. 

###5.6.3 Counts

It is good practice to either count `n()` or count non-missing values `sum(!is.na(x))` to make sure conclusions aren't drawn on small amounts of data. Example:
```{r}
delays <- not_cancelled %>% 
  group_by(tailnum) %>% 
  summarise(
    delay = mean(arr_delay)
  )

ggplot(data = delays, mapping = aes(x = delay)) + 
  geom_freqpoly(binwidth = 10)
```

Get more insight if you plot the number of flights vs average delay:
```{r}
delays <- not_cancelled %>% 
  group_by(tailnum) %>% 
  summarise(
    delay = mean(arr_delay, na.rm = TRUE),
    n = n()
  )

ggplot(data = delays, mapping = aes(x = n, y = delay)) + 
  geom_point(alpha = 1/10)
```

There is greater variation in the average delay when there are few flights. When you plot a mean (or other summary) vs group size, variation decreases as the sample size increases. Can also filter out groups that are small:
```{r}
delays %>% 
  filter(n > 25) %>% 
  ggplot(mapping = aes(x = n, y = delay)) + 
    geom_point(alpha = 1/10)
```

```{r, include=FALSE}
library(Lahman)

```

There's another common variation of this type of pattern. When plotting the skill of the batter (measured by batting average `ba`) against the number of opportunities to hit the ball (measured by at bat `ab`), there are two patterns:  
1. The variation in our aggregate decreases as we get more data points.  
2. There's a positive correlation between skill `ba` and opportunities to hit the ball `ab` because the teams control who gets to play.  
```{r}
# Convert to a tibble so it prints nicely
batting <- as_tibble(Lahman::Batting)

batters <- batting %>% 
  group_by(playerID) %>% 
  summarise(
    ba = sum(H, na.rm = TRUE) / sum(AB, na.rm = TRUE),
    ab = sum(AB, na.rm = TRUE)
  )

batters %>% 
  filter(ab > 100) %>% 
  ggplot(mapping = aes(x = ab, y = ba)) +
    geom_point() + 
    geom_smooth(se = FALSE)
#> `geom_smooth()` using method = 'gam'
```


This has important implications for ranking. Sorting on `desc(ba)`, these players are lucky, not skilled:
```{r}
batters %>% 
  arrange(desc(ba))
```

###5.6.4 Useful summary functions

Measures of location: `mean(x)` which is the sum divided by the length or `median(x)` where 50% of `x` is above it and 50% is below it.  

Sometimes can be useful to combine aggregation with subsetting (which we haven't learned about yet):
```{r}
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(
    avg_delay1 = mean(arr_delay),
    avg_delay2 = mean(arr_delay[arr_delay > 0]) # the average positive delay
  )
```

Measures of spread: `sd(x)` which is the standard deviation, `IQR(x)` which is the interquartile range, or `mad(x)` which is the median absolute deviation. `IQR(x)` and `mad(x)` are rough equivalents that are more useful if there are outliers in the data.

```{r}
# Why is distance to some destinations more variable than to others?
not_cancelled %>% 
  group_by(dest) %>% 
  summarise(distance_sd = sd(distance)) %>% 
  arrange(desc(distance_sd))
```

Measures of rank: `min(x)`, `quantile(x, 0.25)` which is a generalization of the median (specifically here it will find a value of `x` that is greater than 25% of the values and less than the remaining 75%), or `max(x)`.
```{r}
# When do the first and last flights leave each day?
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(
    first = min(dep_time),
    last = max(dep_time)
  )
```

Measures of position: `first(x)`, `nth(x, 2)`, or `last(x)`. Work similarly to `x[1]`, `x[2]`, and `x[length(x)]` but lets you set a default value if that position does not exist ((i.e. youâ€™re trying to get the 3rd element from a group that only has two elements).
```{r}
#Find first and last departure for each day
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(
    first_dep = first(dep_time), 
    last_dep = last(dep_time)
  )
```

These are complemenary to filtering on ranks:
```{r}
not_cancelled %>% 
  group_by(year, month, day) %>% 
  mutate(r = min_rank(desc(dep_time))) %>% 
  filter(r %in% range(r))
```

Counts: `n()` which takes no arguments and returns the size of the current group. For number of non-missing values use `sum(!is.na(x))`. For number of unique values use `n_distinct(x)`.
```{r}
# Which destinations have the most carriers?
not_cancelled %>% 
  group_by(dest) %>% 
  summarise(carriers = n_distinct(carrier)) %>% 
  arrange(desc(carriers))
```

If all you want is count:
```{r}
not_cancelled %>% 
  count(dest)
```

If you want to weight a variable:
```{r}
#Total number of miles a plane flew
not_cancelled %>% 
  count(tailnum, wt = distance)
```

Counts and proportions of logical values: `sum(x>10)` or `mean(y==0)`. When used with numeric functions `TRUE` is converted to 1 and `FALSE` to 0 making `sum(x)` give number of `TRUE` in `x` and `mean(x)` gives proportion.
```{r}
# How many flights left before 5am? (these usually indicate delayed
# flights from the previous day)
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(n_early = sum(dep_time < 500))

# What proportion of flights are delayed by more than an hour?
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(hour_perc = mean(arr_delay > 60))
```

###5.6.5 Grouping by multiple variables

When grouping by multiple variables, each summary peels off one level of the grouping, making it easy to roll up a data set:
```{r}
daily <- group_by(flights, year, month, day)
(per_day   <- summarise(daily, flights = n()))

(per_month <- summarise(per_day, flights = sum(flights)))

(per_year  <- summarise(per_month, flights = sum(flights)))
```

It's ok to progressively roll up sums and counts, but need to think about weighting means and variances and not possible to do it exactly for rank-based statistics like the median. The sum of groupwise sums is the overall sum, but the median of groupwise medians is not the overall median.

###5.6.6 Ungrouping

To  remove grouping, and return to operations on ungrouped data, use `ungroup()`.
```{r}
daily %>% 
  ungroup() %>%             # no longer grouped by date
  summarise(flights = n())  # all flights
```

###5.6.7 Exercises

**1. Brainstorm at least 5 different ways to assess the typical delay characteristics of a group of flights. Consider the following scenarios:**  

* A flight is 15 minutes early 50% of the time, and 15 minutes late 50% of the time.
```{r}
not_cancelled <- flights %>% 
  filter(!is.na(dep_delay), !is.na(arr_delay))
#First way
not_cancelled %>% group_by(year, month, day) %>% summarise(median = median(filter(arr_delay==15 | arr_delay==-15)))

#Second way
not_cancelled %>% group_by(year, month, day) %>% summarise(median = median(filter(dep_delay==15 | dep_delay==-15)))

#Third way
not_cancelled %>% group_by(year, month, day) %>% filter(arr_delay==15, arr_delay==-15) %>% summarise(arr_delay)

#Fourth way
not_cancelled %>% group_by(year, month, day) %>% filter(dep_delay==15, dep_delay==-15) %>% summarise(dep_delay)
```

* A flight is always 10 minutes late. 
```{r}
#First way
not_cancelled %>% group_by(year, month, day) %>% filter(arr_delay==10) %>% summarise(arr_delay)

#Second way
not_cancelled %>% group_by(year, month, day) %>% filter(dep_delay==10) %>% summarise(dep_delay)

```

* A flight is 30 minutes early 50% of the time, and 30 minutes late 50% of the time.  
```{r}
#First way
not_cancelled %>% group_by(year, month, day) %>% summarise(median = median(filter(arr_delay==30 | arr_delay==-30)))

#Second way
not_cancelled %>% group_by(year, month, day) %>% summarise(median = median(filter(dep_delay==30 | dep_delay==-30)))

#Third way
not_cancelled %>% group_by(year, month, day) %>% filter(arr_delay==30, arr_delay==-30) %>% summarise(arr_delay)

#Fourth way
not_cancelled %>% group_by(year, month, day) %>% filter(dep_delay==30, dep_delay==-30) %>% summarise(dep_delay)
```

* 99% of the time a flight is on time. 1% of the time it's 2 hours late. 
```{r}
#First way
not_cancelled %>% group_by(year, month, day) %>% filter(arr_delay >= 120) %>% summarise(onepercent = quantile(arr_delay, 0.01))

#Second way
not_cancelled %>% group_by(year, month, day) %>% filter(dep_delay >= 120) %>% summarise(onepercent = quantile(dep_delay, 0.01))

```


**Which is more important, arrival delay or departure delay?**  
_Personally I think arrival delay is more important because it is mor inconvenient than bein delayed departing._

**2. Come up with another approach that will give you the same outpt as `not_cancelled %>% count(tailnum, wt = distance)` without using `count()`.**  
_This "sums" the total miles the plane flew. There are other ways to do that._
```{r}
not_cancelled %>% group_by(tailnum, distance) %>% summarise(tailnum)
```


**3. Our definition of cancelled flights `is.na(dep_delay) | is.na(arr_delay)` is slightly suboptimal. Why? Which is the most important column?**  
_If a flight is perfectly on time it will have_ `NA` _for both departure delay and arrival delay. If_ `is.na(air_time)` _was included, this would confirm the flight did not take place at all._

**4. Look at the number of cancelled flights per day. Is there a pattern? Is the proportion of cancelled flights related to the average delay?**
```{r}
cancelled <- flights %>% filter(is.na(dep_delay), is.na(arr_delay))

cancelled %>% group_by(year, month, day) %>% summarise(nofly = count(air_time))

not_cancelled %>% group_by(year, month, day) %>% summarise(avg_delay = mean(arr_delay))
```


**5. Which carrier has the worst delays? Challenge: can you disentangle the effects of bad airports vs. bad carriers? Why/why not? (Hint: think about `flights %>% group_by(carrier, dest) %>% summarise(n())`.**
```{r}
not_cancelled %>% group_by(carrier) %>% filter(dep_delay > 0, arr_delay > 0) %>% arrange(desc(dep_delay), desc(arr_delay)) %>% summarise(n())
```


**6. What does the `sort` argument to `count()` do. When might you use it?**
_If sort is set to TRUE, it will sort output in descending order of n. This might be useful in instances where you want a descending order of data but either don't want to or forgot how to do it with the arrange and desc commands._

##5.7 Grouped mutates and filters  

Grouping is most useful with `summarise()` but there are also useful operations with `mutate()` and `filter()`.
```{r}
#Find the worst members of each group:
flights_sml %>% 
  group_by(year, month, day) %>%
  filter(rank(desc(arr_delay)) < 10)

#Find all groups bigger than a threshold:
popular_dests <- flights %>% 
  group_by(dest) %>% 
  filter(n() > 365)
popular_dests

#Standardize to compute per group metrics
popular_dests %>% 
  filter(arr_delay > 0) %>% 
  mutate(prop_delay = arr_delay / sum(arr_delay)) %>% 
  select(year:day, dest, arr_delay, prop_delay)
```

A grouped filter is a grouped mutate followed by an ungrouped filter. Window functions are most useful here vs the summary functions that are used for summaries.

###Window Functions and grouped mutate/filter

A window function is a variation on an aggregation function. Examples: `cumsum() cummean() rank() lead() lag()`.
```{r}
#Some uses and examples
batting <- select(tbl_df(Batting), playerID, yearID, teamID, G, AB:H) 
batting <- arrange(batting, playerID, yearID, teamID)
players <- group_by(batting, playerID)

# For each player, find the two years with most hits
filter(players, min_rank(desc(H)) <= 2 & H > 0)
# Within each player, rank each year by the number of games played
mutate(players, G_rank = min_rank(G))

# For each player, find every year that was better than the previous year
filter(players, G > lag(G))
# For each player, compute avg change in games played per year
mutate(players, G_change = (G - lag(G)) / (yearID - lag(yearID)))

# For each player, find all where they played more games than average
filter(players, G > mean(G))
# For each, player compute a z score based on number of games played
mutate(players, G_z = (G - mean(G)) / sd(G))
```

Ranking and ordering functions: `row_number(), min_rank(), dense_rank(), cume_dist(), percent_rank(), ntile()`. These take a vector to order by and return various types of rank. Use `desc()` to rank from highest to lowest. This is unrelated to aggregation functions.  
```{r}
x <- c(1, 1, 2, 2, 2)

row_number(x)
min_rank(x)
dense_rank(x)
cume_dist(x) #Porportion of values less than or equal to current value
percent_rank(x)

# Selects best two years
filter(players, min_rank(desc(G)) < 2)

# Selects best 10% of years
filter(players, cume_dist(desc(G)) < 0.1)

by_team_player <- group_by(batting, teamID, playerID)
by_team <- summarise(by_team_player, G = sum(G))
by_team_quartile <- group_by(by_team, quartile = ntile(G, 4)) #ntile divides data into n evenly sized buckets
summarise(by_team_quartile, mean(G))
```


Offsets: `lead(), lag()`. Allows access of the previous and next values in a vector. Makes it easy to compute differences and trends. Produce offset versions of an input vector that is either ahead of or behind the original vector. `lag()` is more convenient than `diff()` because for `n` inputes, `diff()` returns `n-1` outputs. Optional `order_by()` argument. If set, instead of using the row order to determine order, the functions will use another variable. This is important with unsorted data or you want to sort one way and lag another. Unrelated to aggregation functions as well.  
```{r}
x <- 1:5
lead(x)
lag(x)

#Compute differences or percent changes
# Compute the relative change in games played
mutate(players, G_delta = G - lag(G))

#Find when a value changes
# Find when a player changed teams
filter(players, teamID != lag(teamID))

#What happens if I don't specify order_by
df <- data.frame(year = 2000:2005, value = (0:5) ^ 2)
scrambled <- df[sample(nrow(df)), ]

wrong <- mutate(scrambled, running = cumsum(value))
arrange(wrong, year)
right <- mutate(scrambled, running = order_by(year, cumsum(value)))
arrange(right, year)

```


Cumulative aggregates: `cumsum(), cummin(), cummax(), cumall(), cumany(), cummean()`. `cumany()` and `cumall()` are useful for selecting all rows up to or all rows after a condition. Can also give order with `order_by()` or `with_order()` as a separate function.   
```{r}
#Find all records for a player after they played a year with 150 games
filter(players, cumany(G > 150))

x <- 1:10
y <- 10:1
order_by(y, cumsum(x))
```


Rolling aggregates: implemented in other packages.  

Recycled aggregates: an aggregate is repeated to match the length of the input. Not needed in R because R does that automatically. Easy to select values that are higher or lower than a summary.  
```{r}
#Find all records greater than the mean or less than the median
filter(players, G > mean(G))
filter(players, G < median(G))

#ntile can be used to achieve same effect as medain or quantile
filter(players, ntile(G, 2) == 2)

#Compute "career year" or the number of years a player has played since they entered the league
mutate(players, career_year = yearID - min(yearID) + 1)

#Or compute a z-score
mutate(players, G_z = (G - mean(G)) / sd(G))
```

The rest of the vignette is about window functions in SQL which is not applicable to this lesson.

###5.7.1 Exercises  

**1. Refer back to the lists of useful mutate and filtering functions. Describe how each operation changes when you combine it with grouping.**  

**2. Which plane (`tailnum`) has the worst on-time record?**  

**3. What time of day should you fly if you want to avoid delays as much as possible?**

**4. For each destination, compute the total minutes of delay. For each, flight, compute the proportion of the total delay for its destination.**

**5. Delays are typically temporally correlated: even once the problem that caused the initial delay has been resolved, later flights are delayed to allow earlier flights to leave. Using `lag()` explore how the delay of a flight is related to the delay of the immediately preceding flight.**  

**6. Look at each destination. Can you find flights that are suspiciously fast? (i.e. flights that represent a potential data entry error). Compute the air time a flight relative to the shortest flight to that destination. Which flights were most delayed in the air?**  

**7. Find all destinations that are flown by at least two carriers. Use that information to rank the carriers.**  

**8. For each plane, count the number of flights before the first delay of greater than 1 hour.**  

#Chapter 6: Workflow: scripts  

###6.3 Practice  

**1. Go to the RStudio Tips twitter account, https://twitter.com/rstudiotips and find one tip that looks interesting. Practice using it!**

**2. What other common mistakes will RStudio diagnostics report? Read https://support.rstudio.com/hc/en-us/articles/205753617-Code-Diagnostics to find out.**
